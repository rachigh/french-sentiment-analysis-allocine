{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR-iU2pUHdPm"
      },
      "source": [
        "# Étape 1 : Chargement et préparation du dataset Allociné\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FsnVqwniHiaL"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch accelerate evaluate scikit-learn\n",
        "!pip install pandas numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ42TsscHt6F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl-9T6WlH5dQ"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Utilisation du device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzmXw0PfII59"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CHARGEMENT DU DATASET ALLOCINÉ\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" CHARGEMENT DU DATASET ALLOCINÉ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\" Téléchargement du dataset Allociné depuis Hugging Face...\")\n",
        "\n",
        "\n",
        "# Charger le dataset complet\n",
        "dataset = load_dataset(\"allocine\")\n",
        "\n",
        "print(f\" Dataset Allociné chargé avec succès !\")\n",
        "print(f\" Structure du dataset :\")\n",
        "print(f\"   • Train: {len(dataset['train']):,} avis\")\n",
        "print(f\"   • Validation: {len(dataset['validation']):,} avis\")\n",
        "print(f\"   • Test: {len(dataset['test']):,} avis\")\n",
        "print(f\"   • Total: {len(dataset['train']) + len(dataset['validation']) + len(dataset['test']):,} avis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8UKs-VXIhUB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# EXPLORATION DU DATASET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXPLORATION DU DATASET ALLOCINÉ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Convertir en DataFrames pour l'exploration\n",
        "train_df = dataset['train'].to_pandas()\n",
        "val_df = dataset['validation'].to_pandas()\n",
        "test_df = dataset['test'].to_pandas()\n",
        "\n",
        "print(\" Aperçu des données :\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(f\"\\n Colonnes disponibles : {list(train_df.columns)}\")\n",
        "\n",
        "# Mapping des labels (Allociné utilise 0=négatif, 1=positif)\n",
        "label_mapping = {0: 'Négatif', 1: 'Positif'}\n",
        "print(f\"\\n Mapping des labels : {label_mapping}\")\n",
        "\n",
        "# Distribution des labels\n",
        "print(f\"\\n Distribution des sentiments dans le train :\")\n",
        "train_counts = train_df['label'].value_counts().sort_index()\n",
        "for label, count in train_counts.items():\n",
        "    percentage = count / len(train_df) * 100\n",
        "    print(f\"   {label_mapping[label]}: {count:,} avis ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\n Distribution des sentiments dans le test :\")\n",
        "test_counts = test_df['label'].value_counts().sort_index()\n",
        "for label, count in test_counts.items():\n",
        "    percentage = count / len(test_df) * 100\n",
        "    print(f\"   {label_mapping[label]}: {count:,} avis ({percentage:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsGc6-qOIqFX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# ANALYSE DE LA LONGUEUR DES TEXTES\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n Analyse de la longueur des avis :\")\n",
        "\n",
        "# Calculer les statistiques de longueur\n",
        "train_df['text_length'] = train_df['review'].str.len()\n",
        "train_df['word_count'] = train_df['review'].str.split().str.len()\n",
        "\n",
        "print(f\"   Longueur moyenne: {train_df['text_length'].mean():.0f} caractères\")\n",
        "print(f\"   Longueur médiane: {train_df['text_length'].median():.0f} caractères\")\n",
        "print(f\"   Nombre de mots moyen: {train_df['word_count'].mean():.1f} mots\")\n",
        "print(f\"   Avis le plus court: {train_df['text_length'].min()} caractères\")\n",
        "print(f\"   Avis le plus long: {train_df['text_length'].max()} caractères\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoYDXqMmI7o9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# VISUALISATIONS\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n Création des visualisations...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Distribution des sentiments\n",
        "ax1 = axes[0, 0]\n",
        "labels = [label_mapping[i] for i in train_counts.index]\n",
        "colors = ['red', 'green']\n",
        "wedges, texts, autotexts = ax1.pie(train_counts.values, labels=labels, autopct='%1.1f%%',\n",
        "                                   colors=colors, startangle=90)\n",
        "ax1.set_title('Distribution des sentiments\\n(Dataset d\\'entraînement)', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 2. Distribution de la longueur des textes\n",
        "ax2 = axes[0, 1]\n",
        "ax2.hist(train_df['text_length'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "ax2.axvline(train_df['text_length'].mean(), color='red', linestyle='--',\n",
        "           label=f'Moyenne: {train_df[\"text_length\"].mean():.0f}')\n",
        "ax2.axvline(train_df['text_length'].median(), color='orange', linestyle='--',\n",
        "           label=f'Médiane: {train_df[\"text_length\"].median():.0f}')\n",
        "ax2.set_xlabel('Longueur en caractères')\n",
        "ax2.set_ylabel('Fréquence')\n",
        "ax2.set_title('Distribution de la longueur des avis', fontsize=12, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Longueur par sentiment\n",
        "ax3 = axes[1, 0]\n",
        "for label in [0, 1]:\n",
        "    subset = train_df[train_df['label'] == label]['text_length']\n",
        "    ax3.hist(subset, bins=30, alpha=0.6, label=label_mapping[label], density=True)\n",
        "ax3.set_xlabel('Longueur en caractères')\n",
        "ax3.set_ylabel('Densité')\n",
        "ax3.set_title('Longueur des avis par sentiment', fontsize=12, fontweight='bold')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Nombre de mots\n",
        "ax4 = axes[1, 1]\n",
        "ax4.hist(train_df['word_count'], bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "ax4.axvline(train_df['word_count'].mean(), color='red', linestyle='--',\n",
        "           label=f'Moyenne: {train_df[\"word_count\"].mean():.1f}')\n",
        "ax4.set_xlabel('Nombre de mots')\n",
        "ax4.set_ylabel('Fréquence')\n",
        "ax4.set_title('Distribution du nombre de mots', fontsize=12, fontweight='bold')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KTc0n3NI_sr"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# EXEMPLES D'AVIS PAR SENTIMENT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" EXEMPLES D'AVIS PAR SENTIMENT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for label_id, sentiment_name in label_mapping.items():\n",
        "    print(f\"\\n{sentiment_name.upper()} :\")\n",
        "    examples = train_df[train_df['label'] == label_id]['review'].head(3).tolist()\n",
        "    for i, example in enumerate(examples, 1):\n",
        "        # Tronquer si trop long pour l'affichage\n",
        "        display_text = example[:200] + \"...\" if len(example) > 200 else example\n",
        "        print(f\"  {i}. \\\"{display_text}\\\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4uCwBi3JJXX"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CRÉATION D'UN SOUS-ÉCHANTILLON POUR L'ENTRAÎNEMENT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" CRÉATION D'UN SOUS-ÉCHANTILLON MANAGEABLE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Pour l'entraînement sur Colab, on va prendre un sous-échantillon\n",
        "# Car 160k exemples c'est trop pour un entraînement rapide\n",
        "TRAIN_SAMPLE_SIZE = 2000  # 1000 par classe\n",
        "TEST_SAMPLE_SIZE = 400    # 200 par classe\n",
        "\n",
        "print(f\" Création d'un échantillon d'entraînement de {TRAIN_SAMPLE_SIZE} avis...\")\n",
        "print(f\" Raison : Entraînement plus rapide sur Colab tout en gardant des résultats significatifs\")\n",
        "\n",
        "# Échantillonner de manière stratifiée\n",
        "def stratified_sample(df, n_samples, label_col='label'):\n",
        "    \"\"\"Échantillonne de manière stratifiée\"\"\"\n",
        "    sampled_dfs = []\n",
        "    for label in df[label_col].unique():\n",
        "        label_df = df[df[label_col] == label]\n",
        "        n_per_class = n_samples // len(df[label_col].unique())\n",
        "        sampled_df = label_df.sample(n=min(n_per_class, len(label_df)), random_state=42)\n",
        "        sampled_dfs.append(sampled_df)\n",
        "    return pd.concat(sampled_dfs, ignore_index=True).sample(frac=1, random_state=42)\n",
        "\n",
        "# Créer les échantillons\n",
        "train_sample = stratified_sample(train_df, TRAIN_SAMPLE_SIZE)\n",
        "test_sample = stratified_sample(test_df, TEST_SAMPLE_SIZE)\n",
        "\n",
        "print(f\" Échantillons créés :\")\n",
        "print(f\"   Train: {len(train_sample)} avis\")\n",
        "print(f\"   Test: {len(test_sample)} avis\")\n",
        "\n",
        "# Vérifier la distribution\n",
        "print(f\"\\n Distribution dans l'échantillon d'entraînement :\")\n",
        "sample_counts = train_sample['label'].value_counts().sort_index()\n",
        "for label, count in sample_counts.items():\n",
        "    percentage = count / len(train_sample) * 100\n",
        "    print(f\"   {label_mapping[label]}: {count} avis ({percentage:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "badyzJ7EJWbg"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SAUVEGARDE DES DONNÉES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" SAUVEGARDE DES DONNÉES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_sample_final = train_sample[['review', 'label']].copy()\n",
        "train_sample_final = train_sample_final.rename(columns={'review': 'text'})\n",
        "\n",
        "test_sample_final = test_sample[['review', 'label']].copy()\n",
        "test_sample_final = test_sample_final.rename(columns={'review': 'text'})\n",
        "\n",
        "# Sauvegarder\n",
        "train_sample_final.to_csv('train_data_allocine.csv', index=False)\n",
        "test_sample_final.to_csv('test_data_allocine.csv', index=False)\n",
        "\n",
        "print(f\" Données sauvegardées :\")\n",
        "print(f\"   • train_data_allocine.csv: {len(train_sample_final)} avis\")\n",
        "print(f\"   • test_data_allocine.csv: {len(test_sample_final)} avis\")\n",
        "\n",
        "# Sauvegarder aussi un échantillon du dataset complet pour référence\n",
        "full_test_sample = test_df[['review', 'label']].sample(n=1000, random_state=42)\n",
        "full_test_sample = full_test_sample.rename(columns={'review': 'text'})\n",
        "full_test_sample.to_csv('test_data_allocine_full.csv', index=False)\n",
        "\n",
        "print(f\"   • test_data_allocine_full.csv: 1000 avis (pour évaluation complète)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}